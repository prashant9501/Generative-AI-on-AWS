{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21dc491e-2880-49c0-8993-94a49e6da6b9",
   "metadata": {},
   "source": [
    "# AWS Comprehend\n",
    "\n",
    "The AWS Comprehend demonstrations provided below include:\n",
    "1. **Sentiment Analysis** to determine the overall sentiment of the text.\n",
    "2. **Key Phrase Detection** to extract key information.\n",
    "3. **Entity Detection** to identify named entities.\n",
    "4. **Language Detection** to determine the language of the text.\n",
    "5. **Syntax Analysis** to understand the grammatical structure.\n",
    "6. **Batch Sentiment Analysis** to detect sentiment for multiple texts simultaneously.\n",
    "\n",
    "These examples are intended to give you a good starting point for understanding the various capabilities of AWS Comprehend, which can be particularly useful for NLP tasks like understanding customer feedback, summarizing documents, or categorizing text data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3b9f16-7a5f-434a-8435-11118101fe32",
   "metadata": {},
   "source": [
    "### Step 1: Set Up AWS Credentials and Create the Comprehend Client\n",
    "First, create the AWS Comprehend client using your root keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b9487d-1a7c-4006-881a-c5d4b0741167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Replace these with your AWS access credentials\n",
    "AWS_ACCESS_KEY_ID = \"AKIAQTKG3\"\n",
    "AWS_SECRET_ACCESS_KEY = \"UeFcS0skzPhEQjUn\"\n",
    "AWS_REGION_NAME = \"us-west-2\"\n",
    "\n",
    "# Create the AWS Comprehend client once using root keys\n",
    "comprehend_client = boto3.client(\n",
    "    'comprehend',\n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "    region_name=AWS_REGION_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e58d74-2d96-4295-a70e-4d58b323de9a",
   "metadata": {},
   "source": [
    "### Step 2: Use the Client for AWS Comprehend Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead60594-f5ca-4109-8d1f-ce3e46a85d48",
   "metadata": {},
   "source": [
    "#### Example 1: Detecting Sentiment of Text\n",
    "This example demonstrates how to use AWS Comprehend to detect the sentiment of a given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ca044c9-4bd7-4262-a412-d8835f96e681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: POSITIVE\n",
      "Sentiment Score: {'Positive': 0.9994766116142273, 'Negative': 7.278929115273058e-05, 'Neutral': 0.00041299971053376794, 'Mixed': 3.7619960494339466e-05}\n"
     ]
    }
   ],
   "source": [
    "text = \"I love learning about AWS Comprehend! It's so useful for NLP tasks.\"\n",
    "\n",
    "# Detect sentiment\n",
    "response = comprehend_client.detect_sentiment(\n",
    "    Text=text,\n",
    "    LanguageCode='en'\n",
    ")\n",
    "\n",
    "# Print the sentiment\n",
    "print(f\"Sentiment: {response['Sentiment']}\")\n",
    "print(f\"Sentiment Score: {response['SentimentScore']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9497d5-df74-45bf-8531-8f2f0e00ab90",
   "metadata": {},
   "source": [
    "#### Example 2: Detecting Key Phrases in Text\n",
    "This example shows how to detect key phrases in a given text using AWS Comprehend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61d94ebd-aaf3-4e85-86ae-f976b80f8abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key Phrase: AWS Comprehend, Score: 0.9999397397041321\n",
      "Key Phrase: text data, Score: 0.9999657273292542\n",
      "Key Phrase: key phrases, Score: 0.9999595284461975\n",
      "Key Phrase: entities, Score: 0.9510319828987122\n",
      "Key Phrase: sentiment, Score: 0.7993917465209961\n"
     ]
    }
   ],
   "source": [
    "text = \"AWS Comprehend helps to analyze text data by identifying key phrases, entities, and sentiment.\"\n",
    "\n",
    "# Detect key phrases\n",
    "response = comprehend_client.detect_key_phrases(\n",
    "    Text=text,\n",
    "    LanguageCode='en'\n",
    ")\n",
    "\n",
    "# Print detected key phrases\n",
    "for phrase in response['KeyPhrases']:\n",
    "    print(f\"Key Phrase: {phrase['Text']}, Score: {phrase['Score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9159f2ab-f836-41c6-a0f5-0d77dc1c9c85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c2b9110-6af2-4183-aec8-ba7f1fefb13d",
   "metadata": {},
   "source": [
    "#### Example 3: Detecting Named Entities in Text\n",
    "This example demonstrates how to use AWS Comprehend to detect named entities such as locations, dates, organizations, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6773e089-f218-477c-9e22-32c267ff592f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Amazon Web Services, Type: ORGANIZATION, Score: 0.9979831576347351\n",
      "Entity: Seattle, Type: LOCATION, Score: 0.9988194108009338\n",
      "Entity: 2006, Type: DATE, Score: 0.9995050430297852\n"
     ]
    }
   ],
   "source": [
    "text = \"Amazon Web Services is headquartered in Seattle, and it was founded in 2006.\"\n",
    "\n",
    "# Detect entities\n",
    "response = comprehend_client.detect_entities(\n",
    "    Text=text,\n",
    "    LanguageCode='en'\n",
    ")\n",
    "\n",
    "# Print detected entities\n",
    "for entity in response['Entities']:\n",
    "    print(f\"Entity: {entity['Text']}, Type: {entity['Type']}, Score: {entity['Score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6db89a7-efaa-4c42-8d8a-027cc67096c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e95d1813-4e2a-4f92-b819-4f1ed4930ef8",
   "metadata": {},
   "source": [
    "#### Example 4: Detecting the Dominant Language\n",
    "AWS Comprehend can also detect the dominant language of a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bcad266-61c3-4956-8c43-166b63472535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: fr, Score: 0.7797092795372009\n",
      "Language: en, Score: 0.21162599325180054\n"
     ]
    }
   ],
   "source": [
    "text = \"Bonjour tout le monde! Je m'appelle AWS Comprehend.\"\n",
    "\n",
    "# Detect dominant language\n",
    "response = comprehend_client.detect_dominant_language(\n",
    "    Text=text\n",
    ")\n",
    "\n",
    "# Print detected language\n",
    "for language in response['Languages']:\n",
    "    print(f\"Language: {language['LanguageCode']}, Score: {language['Score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5350b66a-c0f9-4b11-9da0-dac94d2c113a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d407998d-a301-496c-b245-13d02d3109a4",
   "metadata": {},
   "source": [
    "#### Example 5: Detecting Syntax in Text\n",
    "AWS Comprehend can also provide syntactic information, such as parts of speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caf5248c-42a9-4f31-9ac6-41f8f32e64c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: AWS, Part of Speech: PROPN, Score: 1.0\n",
      "Text: Comprehend, Part of Speech: PROPN, Score: 0.9999902248382568\n",
      "Text: is, Part of Speech: VERB, Score: 1.0\n",
      "Text: a, Part of Speech: DET, Score: 1.0\n",
      "Text: great, Part of Speech: ADJ, Score: 1.0\n",
      "Text: tool, Part of Speech: NOUN, Score: 1.0\n",
      "Text: for, Part of Speech: ADP, Score: 1.0\n",
      "Text: natural, Part of Speech: ADJ, Score: 1.0\n",
      "Text: language, Part of Speech: NOUN, Score: 1.0\n",
      "Text: processing, Part of Speech: NOUN, Score: 1.0\n",
      "Text: ., Part of Speech: PUNCT, Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "text = \"AWS Comprehend is a great tool for natural language processing.\"\n",
    "\n",
    "# Detect syntax\n",
    "response = comprehend_client.detect_syntax(\n",
    "    Text=text,\n",
    "    LanguageCode='en'\n",
    ")\n",
    "\n",
    "# Print detected syntax (tokens and part of speech)\n",
    "for token in response['SyntaxTokens']:\n",
    "    print(f\"Text: {token['Text']}, Part of Speech: {token['PartOfSpeech']['Tag']}, Score: {token['PartOfSpeech']['Score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e45cf51-c994-400e-919c-66ba07c2fecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf332c3-9c9d-4677-913f-ce5c078ff4d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3928f43d-5c9d-4cf4-afd0-f6e8288930a2",
   "metadata": {},
   "source": [
    "#### Example 6: Batch Detecting Sentiment for Multiple Texts\n",
    "You can also analyze sentiment for multiple pieces of text at once using batch detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34671bdd-9793-41f1-a97a-cc7b249e59c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Index: 0, Sentiment: POSITIVE, Sentiment Score: {'Positive': 0.999350368976593, 'Negative': 0.00015503648319281638, 'Neutral': 0.0004015220911242068, 'Mixed': 9.309142478741705e-05}\n",
      "\n",
      "Text Index: 1, Sentiment: NEGATIVE, Sentiment Score: {'Positive': 7.55759101593867e-05, 'Negative': 0.999736487865448, 'Neutral': 3.974716310040094e-05, 'Mixed': 0.00014821025251876563}\n",
      "\n",
      "Text Index: 2, Sentiment: POSITIVE, Sentiment Score: {'Positive': 0.6527155637741089, 'Negative': 0.004047862254083157, 'Neutral': 0.33956703543663025, 'Mixed': 0.003669459605589509}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"I am very happy with AWS Comprehend!\",\n",
    "    \"The service was not good at all, I'm disappointed.\",\n",
    "    \"AWS Comprehend makes NLP tasks easier for developers.\"\n",
    "]\n",
    "\n",
    "# Batch detect sentiment\n",
    "response = comprehend_client.batch_detect_sentiment(\n",
    "    TextList=texts,\n",
    "    LanguageCode='en'\n",
    ")\n",
    "\n",
    "# Print the sentiment for each input text\n",
    "for result in response['ResultList']:\n",
    "    print(f\"Text Index: {result['Index']}, Sentiment: {result['Sentiment']}, Sentiment Score: {result['SentimentScore']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7ed756-3079-4a95-8713-3b7d4dba1f30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
